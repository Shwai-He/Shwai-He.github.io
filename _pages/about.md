---
permalink: /
title: "Biography"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a second-year Ph.D. student in the Department of Computer Science at the University of Maryland, College Park, advised by [Prof. Ang Li](https://www.ang-li.com/). 
Previously, I was a research intern advised by [Dr. Tianlong Chen](https://tianlong-chen.github.io/) at Massachusetts Institute of Technology (CSAIL@MIT). 
I used to be a research assistant at the Research Institute of Intelligent Complex Systems at Fudan University, supervised by [Prof.Siqi Sun](https://intersun.github.io/). 
Before that, I was a research intern at JD Explore Academy, supervised by [Dr. Liang Ding](https://openreview.net/profile?id=~Liang_Ding3) and [Prof. Dacheng Tao](https://www.ntu.edu.sg/research/faculty-directory/detail/rp02343). 
My research interests primarily lie in the area of deep learning, model compression, natural language processing (NLP), and AI + X (e.g., health, finance).

[//]: # (I start with data, models, objectives, optimization, and better adaptation to various downstream tasks to investigate how to efficiently, sufficiently, and trustworthily transfer knowledge from large-scale data to the parameters of the pre-training model.)

News
======
  \[09/2024\]: One paper (Efficient Attention) is accepted by [NeurIPS 2024](https://neurips.cc/). \
  \[09/2024\]: One paper (Reformat Alignment) is accepted by [EMNLP 2024](https://2024.emnlp.org/). \
  \[10/2023\]: One paper (Merging Experts into One) is accepted by [EMNLP 2023](https://2023.emnlp.org/). \
  \[05/2023\]: One paper (PAD-Net) is accepted by [ACL 2023](https://2023.aclweb.org/). \
  \[04/2023\]: One paper (NeuralSlice) is accepted by [ICML 2023](https://icml.cc/). \
  \[10/2022\]: One paper (SparseAdapter) is accepted by [EMNLP 2022](https://2022.emnlp.org/). \
  \[08/2022\]: One paper (SD-Conv) is accpeted by [WACV 2023](https://wacv2023.thecvf.com/). \
  \[07/2022\]: üèÜ Ranked 1st (Chinese<=>English, German<=>English, Czech<=>English, English=>Russian), 2nd (Russian=>English, Japanese=>English), and 3rd (English=>Japanese) in General Translation Task in [WMT 2022](https://statmt.org/wmt22/translation-task.html). \
  \[01/2022\]: One paper is accepted by [AAAI-22 KDF](https://aaai-kdf.github.io/kdf2022/).
  

Research Experience
======
<dl><dt><img align="left" width="110" height="110" hspace="10" src="images/Tencent_logo.png" /></dt><dt> Tencent AI Lab, Bellevue, WA</dt>
<d></d>
<dd>06/2023 - 08/2024</dd>
<dd>Efficient ML </dd></dl>

<dl><dt><img align="left" width="110" height="110" hspace="10" src="images/FDU_Logo.png" /></dt><dt> IICS, Fudan University</dt>
<d></d>
<dd>07/2022 - 03/2023</dd>
<dd>AI for Protein, Computational Biology </dd></dl>

<dl><dt><img align="left" width="110" height="110" hspace="10" src="images/JD_logo.png" /></dt><dt> NLP Group, JD Explore Academy</dt>
<d></d>
<dd>02/2022 - 10/2022</dd>
<dd>Machine Learning, Efficient Methods for NLP </dd></dl>


Selected Publications
======
1. __Shwai He__\*, Guoheng Sun\*, Zheyu Shen, Ang Li, 
"***What Matters in Transformers? Not All Attention is Needed***", arXiv. [[Paper](https://arxiv.org/abs/2406.15786)] [[Code](https://github.com/Shwai-He/LLM-Drop)]
2. __Shwai He__\*, Daize Dong\*, Liang Ding, Ang Li, 
"***Demystifying the Compression of Mixture-of-Experts Through a Unified Framework***", arXiv. [[Paper](https://arxiv.org/abs/2406.02500)] [[Code](https://github.com/DaizeDong/Unified-MoE-Compression)]
3. __Shwai He__, Ang Li, Tianlong Chen, 
"***Rethinking Pruning for Vision-Language Models: Strategies for Effective Sparsity and Performance Restoration***", 
arXiv. [[Paper](https://arxiv.org/abs/2404.02424v2)] [[Code](https://github.com/Shwai-He/VLM-Compression)]
4. __Shwai He__, Run-Ze Fan, Liang Ding, Li Shen, Tianyi Zhou, Dacheng Tao, 
"***Merging Experts into One: Improving Computational Efficiency of Mixture of Experts***",
 Proceedings of The 2023 Conference on Empirical Methods in Natural Language Processing 
 (__EMNLP 2023 Oral__). [[Paper](https://aclanthology.org/2023.emnlp-main.907/)] [[Code](https://github.com/Shwai-He/MEO)]
5. __Shwai He__, Liang Ding, Daize Dong, Boan Liu, Fuqiang Yu, Dacheng Tao, 
"***PAD-Net: An Efficient Framework for Dynamic Networks***",
 Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics (__ACL 2023__). [[Paper](https://aclanthology.org/2023.acl-long.803.pdf)] [[Code](https://github.com/Shwai-He/PAD-Net)]
6. __Shwai He__, Liang Ding, Daize Dong, Miao Zhang, Dacheng Tao, 
"***SparseAdapter: An Easy Approach for Improving the Parameter-Efficiency of Adapters***",
 Findings of The 2022 Conference on Empirical Methods in Natural Language Processing (__EMNLP 2022__). [[Paper](https://aclanthology.org/2022.findings-emnlp.160/)] [[Code](https://github.com/Shwai-He/SparseAdapter)]
7. __Shwai He__, Chenbo Jiang, Daize Dong, Liang Ding, "***SD-Conv: Towards the Parameter-Efficiency of Dynamic Convolution***", IEEE/CVF Winter Conference on Applications of Computer Vision, 2023 (__WACV 2023__). [[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/He_SD-Conv_Towards_the_Parameter-Efficiency_of_Dynamic_Convolution_WACV_2023_paper.pdf)]
8. __Shwai He__, Shi Gu, "***Multi-modal Attention Network for Stock Movements Prediction***", The AAAI-22 Workshop on Knowledge Discovery from Unstructured Data in Financial Service (__KDF 2022__). [[Paper](https://aaai-kdf.github.io/kdf2022/assets/pdfs/KDF_22_paper_3.pdf)]
9. Chenbo Jiang, Jie Yang, __Shwai He__, Yu-Kun Lai and Lin Gao. "***NeuralSlice: Neural 3D Triangle Mesh Reconstruction via Slicing 4D Tetrahedral Meshes.***", Proceedings of the 40th International Conference on Machine Learning, 2023 (__ICML 2023__). [[Paper](https://proceedings.mlr.press/v202/jiang23j/jiang23j.pdf)] [[Code](https://github.com/IGLICT/NEURALSLICE)]
10. Changtong Zan, Keqin Peng, Liang Ding, Baopu Qiu, Boan Liu, __Shwai He__, Qingyu Lu, Zheng Zhang, Chuang
Liu, Weifeng Liu, Yibing Zhan and Dacheng Tao, "***Vega-MT: The JD Explore Academy Translation System for WMT***", The Conference on Machine Translation, 2022 (__WMT 2022__). [[Paper](https://aclanthology.org/2022.wmt-1.37/)] 